{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\E}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "$$\n",
    "\\newcommand{\\kernel}{\\mathbf{k}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# My standard magic !  You will see this in almost all my notebooks.\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "import cnn_helper\n",
    "%aimport cnn_helper\n",
    "cnnh = cnn_helper.CNN_Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Layers: Space and Time\n",
    "\n",
    "In our introductory examples\n",
    "- The spatial dimension of output $\\y_\\llp$\n",
    "- Is identical to the spatial dimension of input $\\y_{(\\ll-1)}$\n",
    "\n",
    "There are different choices we can make when \"sliding\" the kernel over the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These choices impact\n",
    "- The spatial dimension of the output\n",
    "- And, in turn, the time requirements of subsequent layers (because of the size)\n",
    "\n",
    "Let's do some quick calculations and then show choices for controlling the space consumed by $y_\\llp$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# CNN Math: Time versus number of parameters\n",
    "\n",
    "Consider input layer $(\\ll-1)$ with \n",
    "- $N$ spatial dimensions\n",
    "- $n_{(\\ll-1)}$ feature maps/channels\n",
    "$$\n",
    "|| \\y_{(\\ll-1)} || = (\\dim_{(\\ll-1),1} \\times \\dim_{(\\ll-1),2} \\times \\ldots \\dim_{(\\ll-1),N} \\times n_{(\\ll-1)} )\n",
    "$$\n",
    "\n",
    "Layer $\\ll$ will apply a Convolution that preserves the spatial dimensions\n",
    "$$\n",
    "|| \\y_\\llp || = (\\dim_{(\\ll-1),1} \\times \\dim_{(\\ll-1),2} \\times \\ldots \\dim_{(\\ll-1),N} \\times n_\\llp )\n",
    "$$\n",
    "\n",
    "For simplicity of presentation: consider the case when $N=2$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How many weights/parameters does layer $\\ll$ consume (i.e, what is size of $\\W_\\llp$ ) ?\n",
    "- Each kernel $\\kernel_{\\llp,j}$ \n",
    "    - Has spatial dimension $(f_\\llp \\times f_\\llp)$\n",
    "    - And \"depth\" $n_{(\\ll-1)}$ (to match the number of input feature maps/channels)\n",
    "- There are $n_\\llp$ kernels in layer $\\ll$\n",
    "\n",
    "So the size of $W_\\llp$ (ignoring the optional bias term per output feature map)\n",
    "$$\n",
    "|| \\W_\\llp || = n_\\llp * (n_{(\\ll-1)} * f_\\llp * f_\\llp )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The part of the product that most concerns us is ($n_\\llp * n_{(\\ll-1)}$)\n",
    "- Values for $n_\\llp, n_{(\\ll-1)}$ in $\\{ 32, 64, 256 \\} $ are not uncommon !\n",
    "- Hence $|| \\W_\\llp ||$ is often easily several thousand\n",
    "- State of the art image recognition models use *several hundred million* weights !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How many multiplications (in the dot product) are required for layer $\\ll$ ?\n",
    "- We will ignore additions (the part of the dot product that reduces pair-wise products to a scalar, and for the bias)\n",
    "- Each kernel $\\kernel_{\\llp,j}$ of dimension \n",
    "$$(f_\\llp \\times f_\\llp \\times n_{(\\ll-1)})$$\n",
    "- Applied over each location in the $(\\dim_{(\\ll-1),1} \\times \\dim_{(\\ll-1),2})$ spatial dimension of the input layer $(\\ll-1)$\n",
    "- There are $n_\\llp$ kernels in layer $\\ll$\n",
    "\n",
    "So the number of multiplications \n",
    "\n",
    "$$\n",
    "n_\\llp * (\\dim_{(\\ll-1),1} * \\dim_{(\\ll-1),2}) * (n_{(\\ll-1)} * f_\\llp * f_\\llp )\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider a grey-scale image of size $(\\dim_{(\\ll-1),1} * \\dim_{(\\ll-1),2}) = (1024 \\times 1024)$\n",
    "- Lower than your cell-phones camera !\n",
    "- Easily several *million* multiplications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Expect the time to train a Neural Network with Convolutional layers to be long !\n",
    "- That's why GPU's are important in training\n",
    "- But GPU's have limited memory so space is important too\n",
    "    - Can control with batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "All of this ignores the final layer $L$\n",
    "- Often a Fully Connected layer implementing Regression or Classification\n",
    "- With $n_L$ output features\n",
    "    - e.g., For Classification over classes in  set $C$, $\\y_{(L)}$ is a One Hot Vector of length $n_L = ||C||$\n",
    "\n",
    "Suppose layer $(L-1)$ has dimension\n",
    "$$\n",
    "|| \\y_{(L-1)} || =  (\\dim_{(L-1),1} \\times \\dim_{(L-1),2}  \\times n_{(L-1)} )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before we can use it as input to the Fully Connected Layer $L$ we flatten it to a vector of length\n",
    "$$\n",
    "(\\dim_{(L-1),1} * \\dim_{(L-1),2}  * n_{(L-1)} )\n",
    "$$\n",
    "\n",
    "The number of weights (ignoring biases) and multiplications is\n",
    "$$\n",
    "|| W_L || =  n_{(L)} * (\\dim_{(L-1),1} * \\dim_{(L-1),2}  * n_{(L-1)} )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- $n_{(L)} * n_{(L-1)}$ on the order of several thousand\n",
    "- $(\\dim_{(L-1),1} * \\dim_{(L-1),2})$ on the order of several million, for images\n",
    "\n",
    "This may not even be feasible !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thus, controlling the size of each layer $\\y_\\llp$ is of great *practical* importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Controlling the output spatial dimensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Padding\n",
    "\n",
    "In our examples thus far\n",
    "- When a location in the spatial dimensions of the input\n",
    "- Is such that, when the kernel is placed there, it extends beyond the input\n",
    "- We have added \"padding\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is not strictly necessary \n",
    "- But has advantage that the spatial dimension of output $\\y_\\llp$ is the same as the input $\\y_{(\\ll-1)}$\n",
    "- One can simply *not* produce an output for such locations\n",
    "- It just means the output spatial dimension shrinks in each dimension by $f_\\llp -1$\n",
    "    - Assuming $f_\\llp$ is odd\n",
    "    - The number of locations in which the kernel extends over the border\n",
    "    - Is Half of the filter size $(f_\\llp -1)/2$ times two (for each edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stride\n",
    "\n",
    "Thus far, we have placed the kernel over *each* location in the spatial dimension of the input layer.\n",
    "\n",
    "This, along with padding, ensures that the spatial dimension of the input and output layers are identical.\n",
    "\n",
    "Consider two adjacent locations in the spatial dimension of the input layer\n",
    "- The values of the input layer that appear in each dot product overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "By placing the kernel over *every other* location of the spatial dimension of the input layer\n",
    "- We may still be able to recognize features\n",
    "- And reduce the spatial dimension of the output layer by a factor of 2 for each dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In general, we can choose to choose to pass over $(S-1)$ locations in the spatial dimension of the input layer\n",
    "- $S$ is called the *stride*\n",
    "- Up until now: $S = 1$\n",
    "- But you are free to choose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Size of output\n",
    " \n",
    "We can combine choices of Padding and Stride to control the spatial dimension of the output layer $\\ll$:\n",
    "\n",
    "Let\n",
    "- $\\dim_{(\\ll-1),j}$ denote the number of elements in spatial dimension $j$ of layer $(\\ll-1)$\n",
    "- $P$ denote the number of elements added as padding on each border\n",
    "- $S$ denote the stride\n",
    "- $f_\\llp$ be the size of the filter (for each spatial dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then the number of elements in spatial dimension $j$ of output layer $\\llp$ is\n",
    "$$\n",
    "\\dim_{\\llp,j} = \\frac{\\dim_{(\\ll-1),j} + 2P - f_\\llp}{S} + 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can see that increasing the stride has the biggest impact on reducing the spatial dimension of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pooling layer\n",
    "\n",
    "There is a layer type with the specific purpose of changing the spatial dimension of the output.\n",
    "\n",
    "This is called a Pooling Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A Pooling Layer combines the information from adjacent locations in the spatial dimension of the input layer.\n",
    "- The \"combining\" operation may be average or maximum\n",
    "- Sacrificing the exact location in the spatial dimension\n",
    "- Often in exchange for reduced space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A Pooling Layer is similar in *some* respects  to a Convolution.\n",
    "\n",
    "Recall that the One Dimensional Convolutional Layer (Conv1d) with a single input feature\n",
    "computes the following for output feature/channel $j$:\n",
    "\n",
    "\n",
    "$$\n",
    "\\y_{\\llp,j} = \n",
    "\\begin{pmatrix}\n",
    "a_\\llp \\left( \\; N(\\y_{(\\ll-1)}, \\W_{\\llp,j}, 1) \\cdot \\W_\\llp \\; \\right) \\\\\n",
    "a_\\llp \\left( \\; N(\\y_{(\\ll-1)}, \\W_{\\llp,j}, 2) \\cdot \\W_\\llp \\; \\right) \\\\\n",
    "\\vdots \\\\\n",
    "a_\\llp \\left( \\; N(\\y_{(\\ll-1)}, \\W_{\\llp,j}, n_{(\\ll-1)} \\cdot \\W_\\llp \\; \\right) \\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The analogous One Dimensional Pooling Layer (Pooling1D) computes\n",
    "$$\n",
    "\\y_{\\llp,j} = \n",
    "\\begin{pmatrix}\n",
    "p_\\llp \\left( \\; N'(\\y_{(\\ll-1)}, f_\\llp, 1) \\; \\right) \\\\\n",
    "p_\\llp \\left( \\; N'(\\y_{(\\ll-1)}, f_\\llp, 2) \\; \\right) \\\\\n",
    "\\vdots \\\\\n",
    "p_\\llp \\left( \\; N'(\\y_{(\\ll-1)}, f_\\llp, n_{(\\ll-1)} \\right) \\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "where\n",
    "$N'( \\; \\y_{(\\ll-1)}, f_\\llp, j \\; )$\n",
    "- selects a subsequence of $\\y_{(\\ll-1)}$ centered at $\\y_{(\\ll-1), \\ldots, j}$\n",
    "- of length $f_\\llp$\n",
    "\n",
    "and\n",
    "$p_\\llp$ is a *pooling operation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, similar to a Convolutional Layer, the Pooling Layer\n",
    "- Selects a region of length $f_\\llp$\n",
    "- Centered at each location in the spatial dimension of the input layer $(\\ll-1)$\n",
    "\n",
    "and produces a value in the corresponding spatial location of output layer $\\ll$\n",
    "- That *summarizes* the selected region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Observe that\n",
    "- There are *no* weights\n",
    "- No dot product\n",
    "- Just a pooling operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Similar to Convolution, we can extend pooling to higher spatial dimension ($N > 1$) and higher\n",
    "number of input channels $n_{(\\ll-1)} > 1$.\n",
    "\n",
    "Suppose the input $\\y_{(\\ll-1)}$ is $(N+1)$ dimensional of shape \n",
    "$$\n",
    "|| \\y_{(\\ll-1)} || = (\\dim_{(\\ll-1),1} \\times \\dim_{(\\ll-1),2} \\times \\ldots \\dim_{(\\ll-1),N} \\times n_{(\\ll-1)} )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pooling:\n",
    "\n",
    "- Selects an $N$-dimensional region, where each dimension is of length $f_\\llp$\n",
    "- Centered at each location in the spatial dimension\n",
    "    - Of a **single feature map $j$** of the input layer $(\\ll-1)$:  $\\y_{(\\ll-1), \\ldots, j}$\n",
    "\n",
    "and produces a value in the corresponding spatial location of output layer $\\ll$\n",
    "- That *summarizes* the selected region by applying $p_\\llp$ to the selected region\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pooling with a stride $S > 1$\n",
    "- \"Down samples\" the spatial dimension\n",
    "- Sacrificing some information about locality\n",
    "\n",
    "It effectively asks the question\n",
    "- Does the feature exist in a broader neighborhood of the spatial dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is a two dimensional example with a filter size and stride of 2:\n",
    "- $N = 2$\n",
    "- $f_\\llp = 2$\n",
    "- $S = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "    <br>\n",
    "    <center><strong>Conv 2D: Pooling (Max/Average)<strong></center>\n",
    "    <br>\n",
    "<img src=images/W9_L3_S32_PoolingLayer.png width=\"60%\">/<br>\n",
    "    <!-- edX: Original: <img src=\"images/PoolingLayer.jpg\"> replace by EdX created image -->\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The key difference between Pooling and Convolution (other than the absence of the dot product and kernel weights)\n",
    "- The pooling operation is applied to each input feature map *separately*\n",
    "- Versus *all the input feature maps* at a given location in the spatial dimension of the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pooling operations\n",
    "- Max pooling\n",
    "    - Maximum over the selected region\n",
    "    - Good for answering the question: \"Does the feature exist\" in the neighborhood\n",
    "- Average pooling\n",
    "    - average over the selected region\n",
    "    - \"blurs\" the location in the spatial dimension when it is unimportant or highly variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Global Pooling  \n",
    "\n",
    "*Each* feature map $j$ of the input layer ($\\y_{(\\ll-1),\\ldots,j}$)\n",
    "- Is summarized by a single value produced by Max Pooling operation $p'_\\llp$\n",
    "\n",
    "$$\n",
    "\\y_{\\llp,j} = p'_\\llp( \\y_{(\\ll-1), \\ldots, j} )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "    <br>\n",
    "    <center><strong>Conv 2D: Global Pooling (Max/Average)</strong> </center>\n",
    "    <br>\n",
    "<img src=images/W9_L3_S36_GlobalPoolingLayer.png width=\"60%\">\n",
    "    <!-- edX: Original: <img src=\"images/GlobalPoolingLayer.png\"> replace by EdX created image -->\n",
    "    <br>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice that each input feature map has been reduced to a single value in the output.\n",
    "- No spatial dimension in $\\y_\\llp$ (hence no \"$\\ldots$\")\n",
    "\n",
    "The Global Pooling operation effectively asks the question\n",
    "- Does the feature occur *anywhere* in the feature map ?\n",
    "- Losing information about the exact location in the spatial dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Global pooling operations\n",
    "\n",
    "- Global average pooling\n",
    "    - Maximum over the feature map\n",
    "- K-Max pooling\n",
    "    - replace one dimension of the volume with the $K$ largest elements of the dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review \n",
    "\n",
    "Let's summarize our knowledge of controlling the size of $\\y_{(\\ll-1)}$:\n",
    "- Controlling spatial dimensions\n",
    "    - Increase stride\n",
    "    - Pooling\n",
    "        - Global average pooling often used in final Convolutional Layer\n",
    "- Control number of feature maps per layer\n",
    "    - Choice of $n_{\\llp,1}$\n",
    "    - Kernel size $f_\\llp = 1$\n",
    "        - preserve spatial dimension\n",
    "        - change number of feature maps from $n_{(\\ll-1),1}$ to $n_{\\llp,1}$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Striding and Pooling\n",
    "- increase receptive field\n",
    "- typically small values (e.g., $S=2$) \n",
    "    - limited reduction\n",
    "\n",
    "Kernel size $f_\\llp = 1$\n",
    "- reduction depends on the ratio of $n_{\\llp,1}$ to $n_{(\\ll-1),1}$\n",
    "    - unlimited reduction possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Kernel size 1\n",
    "\n",
    "A less obvious way to control the size of $\\y_\\llp$ is to use a kernel with $f_\\llp = 1$\n",
    "\n",
    "Why might that be ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recall that a Convolutional Layer\n",
    "- Preserves the spatial dimension\n",
    "- Replaces the channel/feature dimension (number of feature maps)\n",
    "\n",
    "\n",
    "That is\\\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "|| \\y_{(\\ll-1)} || & = & (\\dim_{(\\ll-1),1} \\times \\dim_{(\\ll-1),2} \\times \\ldots \\dim_{(\\ll-1),N }, & \\mathbf{n_{(\\ll-1)}} ) \\\\\n",
    "|| \\y_\\llp || &  = & (\\dim_{(\\ll-1),1} \\times \\dim_{(\\ll-1),2} \\times \\ldots \\dim_{(\\ll-1),N},  &\\mathbf{n_\\llp} )\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So a kernel of size $f_\\llp =1$ in all $N$ spatial dimensions\n",
    "- With \"depth\" $n_{(\\ll-1)}$\n",
    "- Is just a way to resize $\\y_{(\\ll-1)}$ from $n_{(\\ll-1)}$ feature maps to a *single* feature map\n",
    "    - That sums, across feature maps, the elements in each feature map at the same spatial location\n",
    "\n",
    "In other words:\n",
    "- Yet another way to reduce the size of $\\y_\\llp$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Receptive field\n",
    "\n",
    "The filter size $f_\\llp$ also plays a role in the space and time requirements of a Convolutional Layer.\n",
    "\n",
    "It turns out that\n",
    "- We can achieve the effect of a large $f_\\llp$\n",
    "- With a smaller $f_\\llp$ in conjunction with *more* Convolutional Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The *receptive field* of a layer $\\ll$ feature at a single spatial location in feature map $k$\n",
    "- are the spatial locations of Layer 0 (input) features that affect this single feature\n",
    "\n",
    "For ease of notation:\n",
    "- we assume $N=2$ as the dimension of the kernel\n",
    "- we assume that all $N$ dimensions of the kernel are the same ($f_\\llp$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can determine spatial locations of the layer $0$ features influencing a single layer $\\ll$ location  by working backwards from layer $\\ll$\n",
    "- As we will demonstrate shortly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So we will assume without loss of generality that\n",
    "- the \"height\" and \"width\" of a single kernel kernel is $(f \\times f)$\n",
    "- the full dimensionality of a single layer $\\ll$ kernel is $(f \\times f \\times n_{(\\ll-1)})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Increasing the Receptive Field\n",
    "\n",
    "There are several ways to \"widen\" the receptive field\n",
    "- Increasing $f_\\llp$, the size of the kernel\n",
    "- Stacking Convolutional Layers\n",
    "- Stride\n",
    "- Pooling\n",
    "\n",
    "Striding and Pooling also have the effect of reducing the size of the output feature map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Increase the size of the kernel\n",
    "\n",
    "Although this is the most *obvious* way of increasing the receptive field, we tend to avoid it !\n",
    "\n",
    "We will see that adding layers is a more efficient way of achieving a bigger receptive field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Stacking Convolutional Layers\n",
    "\n",
    "Let's introduce the idea of stacking multiple Convolutional Layers using $N=1$.\n",
    "\n",
    "Consider\n",
    "- $N=1$\n",
    "- $f_\\llp = f_{(\\ll-1)} = 3$\n",
    "- $(L-1) =2$: Two Convolutional Layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "    <br>\n",
    "    <center><h3>Conv 1D Receptive field: 2 layers</h3></center>\n",
    "    <br>\n",
    "<img src=images/W9_L3_S50_Conv1d_receptive.png width=\"80%\">\n",
    "    <!-- edX: Original: <img src=\"images/Conv1d_receptive.jpg\"> replace by EdX created image -->\n",
    "    <br>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The elements in $\\y_\\llp$\n",
    "- Are colored\n",
    "- The same color as the elements of $\\y_{(\\ll-1)}$ that they depend on\n",
    "\n",
    "Each element of layer $\\ll$ depends on $f_\\llp = 3$ elements of layer $(\\ll-1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider the element in the center of the second layer: $y_{(\\ll+1)}$, i.e., $y_{(\\ll+1), \\ldots, 3}$\n",
    "- It depends on the Red, Light Blue and Pink elements of $\\y_\\llp$\n",
    "- Which in turn depend on the Red, Light Blue and Pink elements of $\\y_{(\\ll-1)}$\n",
    "- This includes $5$ elements of $\\y_{(\\ll-1)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So the Two layer network with $f_\\llp = f_{(\\ll-1)} = 3$\n",
    "- Is exposed to the *same* layer $(\\ll-1)$ elements\n",
    "- As a Single Convolutional Layer with $f_\\llp = f_{(\\ll-1)} = 5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One can trace an element in layer $\\ll+1$\n",
    "- Backwards through layers\n",
    "- To input layer $0$\n",
    "\n",
    "in order to determine the receptive field of layer $\\ll+1$/\n",
    "\n",
    "**Bottom line**:\n",
    "The size of the receptive field increases with the depth of the layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One can apply similar logic to $N=2$ spatial dimensions.\n",
    "\n",
    "As you go one layer deeper in the NN, the receptive field width and height increase by (2 * *stride*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "    <br>\n",
    "    <center><h3>Conv 2D Receptive field: 2 layers<h3></center>\n",
    "    <br>\n",
    "<img src=images/W9_L3_S57_Conv2d_receptive_2.png width=\"80%\">\n",
    "        <!-- edX: Original: <img src=\"images/Conv2d_receptive_2.png\"> replace by EdX created image -->\n",
    "        <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Receptive field\n",
    "- The spatial locations in layer $\\ll$\n",
    "- Are color coded to match the spatial locations in layer $(\\ll-1)$\n",
    "- That affect it\n",
    "\n",
    "So the yellow location in layer $\\ll$ is a function of the yellow locations in layer $(\\ll-1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The central location in layer $(\\ll+1)$\n",
    "- Is a function of the spatial locations in layer $\\ll$ that are encircled by the dashed square\n",
    "- The layer $\\ll$ locations are a function of **all** the layer $(\\ll-1)$ locations\n",
    "\n",
    "So the receptive field for the central location in layer $(\\ll+1)$\n",
    "- Includes **all** the locations of layer $(\\ll-1)$\n",
    "\n",
    "In other words: the size of the receptive field grows with layer depth.,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "|  Layer  | Receptive field |\n",
    "|-- |-- |\n",
    "1 | $(3 \\times 3)$\n",
    "2 | $(5 \\times 5)$\n",
    "3 | $(7 \\times 7)$\n",
    "$\\vdots$ | $\\vdots$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's compare\n",
    "- The math of 2 layers with $f_\\llp = f_{(\\ll-1)} = 3$\n",
    "- The math of 1 layer with $f_\\llp = 5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In terms of number of weights:\n",
    "- The one layer network uses \n",
    "$$\n",
    "\\begin{array}[lll]\\\\\n",
    "|| \\W || & = & n_\\llp * (n_{(\\ll-1)} * f'\\llp * f'\\llp ) \\\\\n",
    "& = & 25 * n_\\llp * n_{(\\ll-1)} & \\text{ when } f'\\llp = 5\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "- The two layer network uses\n",
    "$$\n",
    "\\begin{array}[lll]\\\\\n",
    "|| \\W_\\llp ||      & = & n_\\llp * (n_{(\\ll-1)} * f_\\llp * f_\\llp ) \\\\\n",
    "|| \\W_{(\\ll+1)} || & = & n_{(\\ll+1)} * (n_\\llp * f_{(\\ll+1)} * f_{(\\ll+1)} ) \\\\\n",
    "|| \\W || & = & || \\W_\\llp ||  + || \\W_{(\\ll+1)} || \\\\\n",
    "         & = & (9 * n_\\llp * n_{(\\ll-1)}) + 9 *( n_\\llp * n_{(\\ll+1)}) ) & \\text{ when } f_\\llp = f_{(\\ll+1)} = 3 \\\\\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The two layer network uses *fewer* weights when\n",
    "$$\n",
    "9 *( n_\\llp * n_{(\\ll+1)}) ) \\lt (25-9) * n_\\llp * n_{(\\ll-1)}\n",
    "$$\n",
    "\n",
    "This will be the case when the number of feature maps in all layers is roughly the same.\n",
    "- The advantage of the smaller network increases as $f'_\\llp -f_\\ll$ increases\n",
    "    - For example: $f'_\\llp = 7$ \n",
    "    - Versus $3$ Convolutional Layers\n",
    "    - With $f_\\llp = f_{(\\ll-1)} = f_{(\\ll+1)} = 3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CNN advantages/disadvantages\n",
    "\n",
    "**Advantages**\n",
    "- Translational invariance\n",
    "    - feature can be anywhere\n",
    "- Locality\n",
    "    - feature depends on nearby features, not the entire set of features\n",
    "    - reduced number of parameters compared to a Fully Connected layer\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Disadvantages**\n",
    "- Output feature map is roughly same size as input\n",
    "    - lots of computation to compute a single output feature\n",
    "        - one per feature of input map\n",
    "    - higher computation cost\n",
    "        - training and inference\n",
    "- Translational invariance not always a positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How many feature maps to use (What value to choose for $n_\\llp$)\n",
    "[Bag of Tricks for Image Classification with CNNs](https://arxiv.org/abs/1812.01187)\n",
    "\n",
    "\n",
    "Remember that a larger value for $n_\\llp$ will increase space and time requirements.\n",
    "\n",
    "One rule of thumb:\n",
    "- For $N=2$\n",
    "- With filter size $f_\\llp$\n",
    "- The number of elements in the spatial dimension of input $\\y_{(\\ll-1)}$ involved in the dot product is\n",
    "$$e = (n_{(\\ll-1)} * f_\\llp * f_\\llp )$$\n",
    "- It may not make sense to create *more* than $e$ output features $n_\\llp > e$\n",
    "    - We would generate more features than input elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inverting convolution\n",
    "\n",
    "The typical flow for multiple layers of Convolutions\n",
    "- Is for the spatial dimension of successive layers to get smaller\n",
    "- By using stride $S > 1$\n",
    "- By using Pooling Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This brings up the question: Can we invert the process ?\n",
    "- That is, go from a smaller spatial dimension back to the spatial dimension of input layer $0$\n",
    "\n",
    "The answer is yes.\n",
    "\n",
    "This process is sometimes called *Deconvolution* or *Transposed Convolution*.\n",
    "- In a Deeper Dive, we relate Convolution to Matrix Multiplication\n",
    "- So the inverting matrix's *dimensions* are the transpose of the matrix implementing the convolution\n",
    "\n",
    "We will revisit this in the lecture addressing \"What is a CNN looking for ?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Technical points\n",
    "\n",
    "## Convolution versus Cross Correlation\n",
    "- math definition of convolution\n",
    "    - dot product of input and *reversed* filter\n",
    "    - we are doing [cross correlation](https://en.wikipedia.org/wiki/Convolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
